# Summary: BERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA

Poerner et al. (2019) build on previous work on the LAMA probe (Petroni et al., 2019) and investigated whether BERT memorises factual knowledge or simply reasons about entity names (e.g. guesses an italian sounding name is Italian). For thus, they created a subset of LAMA called LAMA-UHN (unHelpfulNames) by filtering out facts that easy to guess from the entity names. The performance of BERT drops when using the more difficult subset of facts, thus suggesting that BERT may not actually memorise facts but simply reason about entity names. 

In addition, Poerner et al. (2019) also introduced E-BERT, an extension of BERT in which the entity embeddings are replaced by wikipedia2vec embeddings. This model variant outperforms other baselines on LAMA-UHN. 